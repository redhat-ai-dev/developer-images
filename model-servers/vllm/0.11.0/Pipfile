[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[[source]]
url = "https://download.pytorch.org/whl/cu126/"
verify_ssl = false
name = "pytorch"

[packages]
cmake = "~=3.31.6"
einops= "~=0.8.0"
fastapi = "~=0.120.0"
filelock = "~=3.20.0"
lm-format-enforcer = "==0.11.3"
ninja = "~=1.13.0.0"
numpy = "~=1.26.4"
nvidia-ml-py = "~=12.575.51"
openai = "~=1.109.1"
outlines = "~=0.2.3"
pip = "~=24.0"
prometheus_client = "~=0.23.1"
prometheus-fastapi-instrumentator = "~=7.1.0"
psutil = "~=5.9.8"
py-cpuinfo = "~=9.0.0"
pydantic = "~=2.12.3"
pynvml = "==11.5.3"
ray = "~=2.48.0"
requests = "~=2.31.0"
sentencepiece = "~=0.2.0"
tiktoken = "~=0.12.0"
torch = {version = "==2.9.0+cu126", index = "pytorch"} # Required by vllm 0.11.0 - CUDA 12.1 no longer supported
tokenizers = "~=0.22.1"
transformers = "~=4.57.1"
triton = "==3.5.0"
typing_extensions = "~=4.15.0"
uvicorn = {extras = ["standard"], version = "~=0.38.0"}
vllm = "==0.11.0"
vllm-nccl-cu12 = "==2.18.1.0.4.0"
wheel = "~=0.45.1"
xformers = "==0.0.32.post2" # Required by vllm 0.11.0 with PyTorch 2.8.0

[dev-packages]

[requires]
python_version = "3.11"